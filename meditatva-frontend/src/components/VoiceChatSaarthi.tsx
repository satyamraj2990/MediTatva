import { useState, useEffect, useRef } from "react";
import { Mic, MicOff, Phone, PhoneOff, Volume2 } from "lucide-react";
import { motion, AnimatePresence } from "framer-motion";
import { Button } from "@/components/ui/button";
import { Card } from "@/components/ui/card";
import { Badge } from "@/components/ui/badge";
import { GoogleGenerativeAI } from "@google/generative-ai";
import { toast } from "sonner";

// Initialize Gemini AI
let genAI: GoogleGenerativeAI | null = null;
let apiKeyStatus = { present: false, error: "" };

try {
  const apiKey = import.meta.env.VITE_GEMINI_API_KEY;
  console.log("üîë Checking Gemini API key...");
  console.log("üîë API Key present:", !!apiKey);
  console.log("üîë API Key length:", apiKey?.length || 0);
  
  if (!apiKey) {
    apiKeyStatus.error = "API key not found in environment variables";
    console.error("‚ùå VITE_GEMINI_API_KEY not found in .env file");
    console.error("üìù To fix: Create .env file with: VITE_GEMINI_API_KEY=your_api_key");
  } else if (apiKey === "your_gemini_api_key_here" || apiKey === "your_api_key_here") {
    apiKeyStatus.error = "API key not configured (using placeholder)";
    console.error("‚ùå VITE_GEMINI_API_KEY is still using placeholder value");
    console.error("üìù To fix: Replace with actual API key from https://makersuite.google.com/app/apikey");
  } else {
    genAI = new GoogleGenerativeAI(apiKey);
    apiKeyStatus.present = true;
    console.log("‚úÖ Gemini AI initialized successfully");
    console.log("‚úÖ Using API key:", apiKey.substring(0, 10) + "..." + apiKey.substring(apiKey.length - 4));
  }
} catch (error) {
  apiKeyStatus.error = error instanceof Error ? error.message : "Unknown error";
  console.error("‚ùå Gemini API initialization error:", error);
}

// AI Saarthi Voice System Prompt - Medical Guidance
const VOICE_SAARTHI_PROMPT = `You are AI Saarthi, a caring medical wellness assistant for MediTatva healthcare platform.

IMPORTANT: You MUST respond to EVERY medical query with helpful advice.

Your role:
- Answer ALL health-related questions
- Provide practical medical guidance for common symptoms
- Suggest appropriate medicines with dosages
- Give home remedies and precautions
- Be empathetic, calm, and supportive

Response rules:
1. ALWAYS respond in the SAME language as the user (Hindi or English)
2. For ANY health symptom or medical question:
   - First acknowledge with empathy ("I understand", "‡§Æ‡•à‡§Ç ‡§∏‡§Æ‡§ù‡§§‡§æ ‡§π‡•Ç‡§Ç")
   - Suggest 2-3 suitable OTC medicines with proper dosage
   - Provide 2-3 home remedies or lifestyle tips
   - Mention when to consult a doctor
3. Keep responses conversational and natural (4-7 sentences)
4. NO bullet points - speak naturally
5. Include medicine alternatives when possible

Example responses:

For "‡§Æ‡•Å‡§ù‡•á ‡§∏‡§ø‡§∞‡§¶‡§∞‡•ç‡§¶ ‡§π‡•à":
"‡§Æ‡•Å‡§ù‡•á ‡§∏‡•Å‡§®‡§ï‡§∞ ‡§¶‡•Å‡§ñ ‡§π‡•Å‡§Ü‡•§ ‡§∏‡§ø‡§∞‡§¶‡§∞‡•ç‡§¶ ‡§ï‡•á ‡§≤‡§ø‡§è ‡§Ü‡§™ Combiflam ‡§Ø‡§æ Saridon ‡§≤‡•á ‡§∏‡§ï‡§§‡•á ‡§π‡•à‡§Ç‡•§ ‡§è‡§ï ‡§ó‡•ã‡§≤‡•Ä ‡§≤‡•á‡§Ç ‡§î‡§∞ 6 ‡§ò‡§Ç‡§ü‡•á ‡§¨‡§æ‡§¶ ‡§¶‡•ã‡§¨‡§æ‡§∞‡§æ ‡§≤‡•á ‡§∏‡§ï‡§§‡•á ‡§π‡•à‡§Ç‡•§ ‡§™‡§æ‡§®‡•Ä ‡§ñ‡•Ç‡§¨ ‡§™‡§ø‡§è‡§Ç, ‡§Ü‡§∞‡§æ‡§Æ ‡§ï‡§∞‡•á‡§Ç ‡§î‡§∞ ‡§Æ‡§æ‡§•‡•á ‡§™‡§∞ ‡§†‡§Ç‡§°‡§æ ‡§™‡§æ‡§®‡•Ä ‡§≤‡§ó‡§æ‡§è‡§Ç‡•§ ‡§Ö‡§ó‡§∞ ‡§¶‡§∞‡•ç‡§¶ ‡§¨‡§¢‡§º‡•á ‡§Ø‡§æ 2 ‡§¶‡§ø‡§® ‡§∏‡•á ‡§ú‡•ç‡§Ø‡§æ‡§¶‡§æ ‡§∞‡§π‡•á ‡§§‡•ã ‡§°‡•â‡§ï‡•ç‡§ü‡§∞ ‡§ï‡•ã ‡§¶‡§ø‡§ñ‡§æ‡§è‡§Ç‡•§"

For "I have cold and cough":
"I'm sorry to hear that. For cold and cough, you can take Cheston Cold or Benadryl syrup twice daily. Steam inhalation helps a lot, and drink warm water with honey and ginger. Take rest and avoid cold food. If symptoms persist beyond 5 days or you get high fever, please see a doctor."

For "‡§¨‡•Å‡§ñ‡§æ‡§∞ ‡§π‡•à 101 degree":
"101 ‡§¨‡•Å‡§ñ‡§æ‡§∞ ‡§π‡•à ‡§§‡•ã ‡§ö‡§ø‡§Ç‡§§‡§æ ‡§® ‡§ï‡§∞‡•á‡§Ç‡•§ Dolo 650 ‡§Ø‡§æ Crocin 500 ‡§≤‡•á‡§Ç, ‡§π‡§∞ 6 ‡§ò‡§Ç‡§ü‡•á ‡§Æ‡•á‡§Ç‡•§ ‡§†‡§Ç‡§°‡•á ‡§™‡§æ‡§®‡•Ä ‡§ï‡•Ä ‡§™‡§ü‡•ç‡§ü‡•Ä ‡§Æ‡§æ‡§•‡•á ‡§™‡§∞ ‡§∞‡§ñ‡•á‡§Ç‡•§ ‡§ñ‡•Ç‡§¨ ‡§™‡§æ‡§®‡•Ä ‡§î‡§∞ ‡§®‡•Ä‡§Ç‡§¨‡•Ç ‡§™‡§æ‡§®‡•Ä ‡§™‡§ø‡§è‡§Ç‡•§ ‡§π‡§≤‡•ç‡§ï‡§æ ‡§ñ‡§æ‡§®‡§æ ‡§ñ‡§æ‡§è‡§Ç‡•§ ‡§Ö‡§ó‡§∞ ‡§¨‡•Å‡§ñ‡§æ‡§∞ 102 ‡§∏‡•á ‡§ú‡•ç‡§Ø‡§æ‡§¶‡§æ ‡§π‡•ã ‡§Ø‡§æ 3 ‡§¶‡§ø‡§® ‡§Æ‡•á‡§Ç ‡§†‡•Ä‡§ï ‡§® ‡§π‡•ã ‡§§‡•ã ‡§°‡•â‡§ï‡•ç‡§ü‡§∞ ‡§∏‡•á ‡§Æ‡§ø‡§≤‡•á‡§Ç‡•§"

NEVER say "I cannot help" or refuse to answer medical questions. ALWAYS provide helpful guidance.`;

type VoiceState = "idle" | "listening" | "speaking" | "processing";

interface VoiceChatSaarthiProps {
  onClose: () => void;
}

export const VoiceChatSaarthi = ({ onClose }: VoiceChatSaarthiProps) => {
  const [voiceState, setVoiceState] = useState<VoiceState>("idle");
  const [transcript, setTranscript] = useState<string>("");
  const [lastResponse, setLastResponse] = useState<string>("");
  const [chatSession, setChatSession] = useState<any>(null);
  const [isSupported, setIsSupported] = useState(true);
  const [currentLanguage, setCurrentLanguage] = useState("hi-IN");
  const [isCallActive, setIsCallActive] = useState(false); // Track call state

  // Refs
  const recognitionRef = useRef<any>(null);
  const synthRef = useRef<SpeechSynthesisUtterance | null>(null);
  const voiceStateRef = useRef<VoiceState>("idle"); // Track state in ref for callbacks

  // Check browser support
  useEffect(() => {
    const hasWebSpeech = 'webkitSpeechRecognition' in window || 'SpeechRecognition' in window;
    const hasSynthesis = 'speechSynthesis' in window;
    
    if (!hasWebSpeech || !hasSynthesis) {
      setIsSupported(false);
      toast.error("Your browser doesn't support voice chat. Please use Chrome or Edge.");
    }
  }, []);

  // Initialize AI chat session
  useEffect(() => {
    initializeChatSession();
  }, []);

  const initializeChatSession = async () => {
    try {
      if (!genAI) {
        console.error("‚ùå Gemini AI not initialized - API key issue:", apiKeyStatus.error);
        
        const errorMsg = currentLanguage === "hi-IN" 
          ? "AI ‡§∏‡•á‡§µ‡§æ ‡§ï‡•â‡§®‡•ç‡§´‡§º‡§ø‡§ó‡§∞ ‡§®‡§π‡•Ä‡§Ç ‡§π‡•à‡•§ ‡§ï‡•É‡§™‡§Ø‡§æ ‡§∏‡§™‡•ã‡§∞‡•ç‡§ü ‡§ü‡•Ä‡§Æ ‡§∏‡•á ‡§∏‡§Ç‡§™‡§∞‡•ç‡§ï ‡§ï‡§∞‡•á‡§Ç‡•§"
          : "AI service is not configured. Please contact support team.";
        
        const detailedError = apiKeyStatus.error.includes("not found")
          ? "Missing API Key: Create a .env file in meditatva-frontend/ with VITE_GEMINI_API_KEY=your_key"
          : apiKeyStatus.error.includes("placeholder")
          ? "Invalid API Key: Get a real API key from https://makersuite.google.com/app/apikey"
          : apiKeyStatus.error;
        
        toast.error(detailedError, { duration: 8000 });
        setLastResponse(errorMsg);
        await speakText(errorMsg);
        setIsCallActive(false);
        return;
      }

      console.log("üîß Initializing AI chat session for voice...");
      
      // Initialize model with gemini-2.5-flash (has available quota)
      // Note: gemini-1.5-flash and gemini-2.0-flash may have quota issues
      const model = genAI.getGenerativeModel({
        model: "gemini-2.5-flash"
      });

      const chat = model.startChat({
        generationConfig: {
          temperature: 0.8,
          topP: 0.95,
          topK: 40,
          maxOutputTokens: 2048,
        },
        history: [
          {
            role: "user",
            parts: [{ text: VOICE_SAARTHI_PROMPT }],
          },
          {
            role: "model",
            parts: [{ text: "‡§®‡§Æ‡§∏‡•ç‡§§‡•á‡•§ ‡§Æ‡•à‡§Ç ‡§∏‡§æ‡§∞‡•ç‡§•‡•Ä ‡§π‡•Ç‡§Ç‡•§ ‡§Ü‡§ú ‡§Ü‡§™ ‡§ï‡•à‡§∏‡§æ ‡§Æ‡§π‡§∏‡•Ç‡§∏ ‡§ï‡§∞ ‡§∞‡§π‡•á ‡§π‡•à‡§Ç?" }],
          },
        ],
      });

      setChatSession(chat);
      console.log("‚úÖ Chat session initialized successfully");
      console.log("‚úÖ AI Saarthi is ready to answer medical queries");

      // Start call automatically with greeting
      setIsCallActive(true);
      const greeting = "‡§®‡§Æ‡§∏‡•ç‡§§‡•á‡•§ ‡§Æ‡•à‡§Ç ‡§∏‡§æ‡§∞‡•ç‡§•‡•Ä ‡§π‡•Ç‡§Ç‡•§ ‡§Ü‡§ú ‡§Ü‡§™ ‡§ï‡•à‡§∏‡§æ ‡§Æ‡§π‡§∏‡•Ç‡§∏ ‡§ï‡§∞ ‡§∞‡§π‡•á ‡§π‡•à‡§Ç?";
      setLastResponse(greeting);
      await speakText(greeting);
        
    } catch (error: any) {
      console.error("‚ùå Error initializing chat:", error);
      console.error("Error details:", error instanceof Error ? error.message : String(error));
      
      const errorMsg = currentLanguage === "hi-IN"
        ? "‡§ï‡•â‡§≤ ‡§∂‡•Å‡§∞‡•Ç ‡§ï‡§∞‡§®‡•á ‡§Æ‡•á‡§Ç ‡§µ‡§ø‡§´‡§≤‡•§ ‡§ï‡•É‡§™‡§Ø‡§æ ‡§™‡•Å‡§®‡§É ‡§™‡•ç‡§∞‡§Ø‡§æ‡§∏ ‡§ï‡§∞‡•á‡§Ç‡•§"
        : "Failed to start call. Please try again.";
      
      toast.error("Unable to initialize: " + (error instanceof Error ? error.message : 'Unknown error'));
      setLastResponse(errorMsg);
      await speakText(errorMsg);
      setIsCallActive(false);
    }
  };

  // Initialize speech recognition
  const initRecognition = () => {
    if (recognitionRef.current) {
      console.log("üõë Stopping existing recognition");
      recognitionRef.current.stop();
    }

    const SpeechRecognition = (window as any).webkitSpeechRecognition || (window as any).SpeechRecognition;
    const recognition = new SpeechRecognition();

    recognition.continuous = false; // Stop after one utterance
    recognition.interimResults = false;
    recognition.lang = currentLanguage;

    recognition.onstart = () => {
      console.log("üéôÔ∏è STATE: Listening started");
      setVoiceState("listening");
      voiceStateRef.current = "listening";
    };

    recognition.onresult = async (event: any) => {
      const spokenText = event.results[0][0].transcript;
      console.log("üìù USER SPOKE:", spokenText);
      
      // CRITICAL: Stop recognition immediately
      recognition.stop();
      
      setTranscript(spokenText);
      setVoiceState("processing");
      voiceStateRef.current = "processing";
      console.log("‚öôÔ∏è STATE: Processing");

      // Get AI response
      await getAIResponse(spokenText);
    };

    recognition.onerror = (event: any) => {
      console.error("‚ùå Speech recognition error:", event.error);
      
      if (event.error === "no-speech") {
        toast.info("I didn't hear anything. Listening again...");
        // Auto-restart if call is active
        if (isCallActive && voiceStateRef.current !== "speaking") {
          setTimeout(() => startListening(), 1000);
        } else {
          setVoiceState("idle");
          voiceStateRef.current = "idle";
        }
      } else if (event.error === "not-allowed") {
        toast.error("Microphone permission denied. Please enable it.");
        setVoiceState("idle");
        voiceStateRef.current = "idle";
        setIsCallActive(false);
      } else {
        toast.error("Voice error. Restarting...");
        if (isCallActive) {
          setTimeout(() => startListening(), 1000);
        } else {
          setVoiceState("idle");
          voiceStateRef.current = "idle";
        }
      }
    };

    recognition.onend = () => {
      console.log("üéôÔ∏è Recognition ended. Current state:", voiceStateRef.current);
      
      // Only auto-restart if we're still idle and call is active
      if (voiceStateRef.current === "idle" && isCallActive) {
        console.log("üîÑ Auto-restarting listening");
        setTimeout(() => startListening(), 500);
      }
    };

    recognitionRef.current = recognition;
  };

  // Start listening
  const startListening = () => {
    if (!isSupported) {
      toast.error("Voice chat is not supported in your browser");
      return;
    }

    // CRITICAL: Don't listen while speaking
    if (voiceStateRef.current === "speaking") {
      console.log("‚ö†Ô∏è Cannot listen while speaking");
      return;
    }

    // Cancel any ongoing speech before listening
    if (window.speechSynthesis.speaking) {
      console.log("üõë Canceling ongoing speech");
      window.speechSynthesis.cancel();
    }

    console.log("‚ñ∂Ô∏è Starting listening...");
    initRecognition();
    try {
      recognitionRef.current?.start();
    } catch (error) {
      console.error("‚ùå Failed to start recognition:", error);
      // If already started, ignore
    }
  };

  // Stop listening
  const stopListening = () => {
    console.log("‚èπÔ∏è Stopping listening");
    recognitionRef.current?.stop();
    setVoiceState("idle");
    voiceStateRef.current = "idle";
  };

  // Get AI response with robust error handling
  const getAIResponse = async (userMessage: string) => {
    try {
      console.log("üì§ SENDING TO AI:", userMessage);
      
      // Check if chat session exists
      if (!chatSession) {
        console.error("‚ùå Chat session not initialized");
        throw new Error("Chat session not initialized");
      }

      // Add language context to help AI respond appropriately  
      const messageWithContext = currentLanguage === "hi-IN" && !userMessage.match(/[a-zA-Z]/) 
        ? `${userMessage} (‡§ï‡•É‡§™‡§Ø‡§æ ‡§π‡§ø‡§Ç‡§¶‡•Ä ‡§Æ‡•á‡§Ç ‡§ú‡§µ‡§æ‡§¨ ‡§¶‡•á‡§Ç)`
        : `${userMessage} (please respond in English)`;

      console.log("üì§ Sending with context:", messageWithContext);

      // Send message with timeout and better error handling
      let result: any;
      try {
        console.log("üì° Attempting to send message to Gemini API...");
        console.log("üì° Chat session exists:", !!chatSession);
        console.log("üì° Message to send:", messageWithContext.substring(0, 50) + "...");
        
        result = await Promise.race([
          chatSession.sendMessage(messageWithContext),
          new Promise((_, reject) => 
            setTimeout(() => reject(new Error("AI response timeout after 15s")), 15000)
          )
        ]);
        
        console.log("‚úÖ Message sent successfully, received result");
      } catch (sendError: any) {
        console.error("‚ùå Error sending message to Gemini:", sendError);
        console.error("‚ùå Error name:", sendError?.name);
        console.error("‚ùå Error message:", sendError?.message);
        console.error("‚ùå Error stack:", sendError?.stack);
        console.error("‚ùå Full error object:", JSON.stringify(sendError, Object.getOwnPropertyNames(sendError)));
        
        // Check for network errors
        if (sendError.message?.includes("fetch") || 
            sendError.message?.includes("network") ||
            sendError.message?.includes("Failed to fetch") ||
            sendError.message?.includes("quota") ||
            sendError.message?.includes("429") ||
            sendError.name === "TypeError") {
          console.error("üìä Detected network/quota error");
          console.error("üìä Error details:", {
            name: sendError.name,
            message: sendError.message,
            status: sendError.status
          });
          
          // Check if it's a quota error specifically
          if (sendError.message?.includes("quota") || sendError.message?.includes("429")) {
            throw new Error("QUOTA_EXCEEDED: API rate limit reached. Please wait 1-2 minutes and try again.");
          }
          
          throw new Error("Cannot reach Gemini API. Check if https://generativelanguage.googleapis.com is accessible.");
        }
        
        // Check for CORS errors
        if (sendError.message?.includes("CORS") || 
            sendError.message?.includes("blocked")) {
          throw new Error("API access blocked by browser CORS policy.");
        }
        
        throw sendError;
      }

      // Validate response
      if (!result || !result.response) {
        throw new Error("Invalid AI response structure");
      }

      const responseText = result.response.text();
      console.log("üì• AI RAW RESPONSE:", responseText);

      // Check if response is empty or too short
      if (!responseText || responseText.trim().length === 0) {
        throw new Error("Empty AI response");
      }

      if (responseText.trim().length < 3) {
        throw new Error("Response too short");
      }
      
      // Clean up markdown formatting for voice
      const cleanResponse = responseText
        .replace(/\*\*/g, "")
        .replace(/\*/g, "")
        .replace(/\n+/g, ". ")
        .replace(/[#]+/g, "")
        .replace(/\[.*?\]/g, "") // Remove language tags
        .trim();

      console.log("‚úÖ CLEAN RESPONSE:", cleanResponse);
      setLastResponse(cleanResponse);
      
      // CRITICAL: Speak the response
      await speakText(cleanResponse);
      
    } catch (error: any) {
      console.error("‚ùå AI Response Error:", error);
      console.error("Error type:", error?.constructor?.name);
      console.error("Error message:", error?.message);
      
      // Convert error to string safely
      const errorString = String(error?.message || error || 'unknown error').toLowerCase();
      console.error("Error string:", errorString);
      
      // Provide meaningful, calm fallback based on language and error type
      let fallbackMsg: string;
      
      // Check for specific error types
      const isQuotaError = errorString.includes("quota") || 
                           errorString.includes("429") || 
                           errorString.includes("resource_exhausted") ||
                           errorString.includes("resource exhausted");
      
      const isTimeoutError = errorString.includes("timeout");
      const isSessionError = errorString.includes("session") || errorString.includes("not initialized");
      const isNetworkError = errorString.includes("network") || 
                             errorString.includes("fetch") ||
                             errorString.includes("connection") ||
                             errorString.includes("cors") ||
                             errorString.includes("blocked");
      const isAPIKeyError = errorString.includes("api") && errorString.includes("key");
      
      // Handle different error types with appropriate responses
      if (isAPIKeyError) {
        if (currentLanguage === "hi-IN") {
          fallbackMsg = "‡§Æ‡•Å‡§ù‡•á ‡§ñ‡•á‡§¶ ‡§π‡•à, ‡§∏‡•á‡§µ‡§æ ‡§â‡§™‡§≤‡§¨‡•ç‡§ß ‡§®‡§π‡•Ä‡§Ç ‡§π‡•à‡•§ ‡§ï‡•É‡§™‡§Ø‡§æ ‡§¨‡§æ‡§¶ ‡§Æ‡•á‡§Ç ‡§™‡•Å‡§®‡§É ‡§™‡•ç‡§∞‡§Ø‡§æ‡§∏ ‡§ï‡§∞‡•á‡§Ç‡•§";
        } else {
          fallbackMsg = "Sorry, service is unavailable. Please try again later.";
        }
        toast.error("AI service configuration error. Check API key in .env file.");
      } else if (isNetworkError) {
        if (currentLanguage === "hi-IN") {
          fallbackMsg = "‡§®‡•á‡§ü‡§µ‡§∞‡•ç‡§ï ‡§Æ‡•á‡§Ç ‡§∏‡§Æ‡§∏‡•ç‡§Ø‡§æ ‡§π‡•à‡•§ ‡§ï‡•É‡§™‡§Ø‡§æ ‡§Ö‡§™‡§®‡§æ ‡§ï‡§®‡•á‡§ï‡•ç‡§∂‡§® ‡§ú‡§æ‡§Ç‡§ö‡•á‡§Ç ‡§î‡§∞ ‡§™‡•Å‡§®‡§É ‡§™‡•ç‡§∞‡§Ø‡§æ‡§∏ ‡§ï‡§∞‡•á‡§Ç‡•§";
        } else {
          fallbackMsg = "Network issue detected. Please check your connection and try again.";
        }
        toast.error("Cannot connect to Gemini API. Check network/firewall settings.", { duration: 6000 });
        console.error("üí° TIP: If using VPN or proxy, try disabling it temporarily");
      } else if (isQuotaError) {
        if (currentLanguage === "hi-IN") {
          fallbackMsg = "‡§Æ‡•Å‡§ù‡•á ‡§ñ‡•á‡§¶ ‡§π‡•à, ‡§Ö‡§≠‡•Ä ‡§¨‡§π‡•Å‡§§ ‡§∏‡§æ‡§∞‡•á ‡§≤‡•ã‡§ó ‡§Æ‡•Å‡§ù‡§∏‡•á ‡§¨‡§æ‡§§ ‡§ï‡§∞ ‡§∞‡§π‡•á ‡§π‡•à‡§Ç‡•§ ‡§ï‡•É‡§™‡§Ø‡§æ ‡§è‡§ï ‡§Æ‡§ø‡§®‡§ü ‡§Æ‡•á‡§Ç ‡§´‡§ø‡§∞ ‡§∏‡•á ‡§ï‡•ã‡§∂‡§ø‡§∂ ‡§ï‡§∞‡•á‡§Ç‡•§";
        } else {
          fallbackMsg = "Sorry, I'm talking to many people right now. Please try again in a minute.";
        }
        toast.error("API quota exceeded. Please wait 1 minute.", { duration: 5000 });
      } else if (isTimeoutError) {
        if (currentLanguage === "hi-IN") {
          fallbackMsg = "‡§Æ‡•Å‡§ù‡•á ‡§•‡•ã‡§°‡§º‡§æ ‡§∏‡§Æ‡§Ø ‡§≤‡§ó ‡§∞‡§π‡§æ ‡§π‡•à‡•§ ‡§ï‡•É‡§™‡§Ø‡§æ ‡§´‡§ø‡§∞ ‡§∏‡•á ‡§¨‡§§‡§æ‡§è‡§Ç‡•§";
        } else {
          fallbackMsg = "I'm taking a moment. Please try again.";
        }
      } else if (isSessionError) {
        if (currentLanguage === "hi-IN") {
          fallbackMsg = "‡§Æ‡•à‡§Ç ‡§Ø‡§π‡§æ‡§Å ‡§π‡•Ç‡§Ç‡•§ ‡§Ü‡§™ ‡§ï‡•à‡§∏‡§æ ‡§Æ‡§π‡§∏‡•Ç‡§∏ ‡§ï‡§∞ ‡§∞‡§π‡•á ‡§π‡•à‡§Ç?";
        } else {
          fallbackMsg = "I'm here. How are you feeling?";
        }
        // Try to reinitialize session
        setTimeout(() => initializeChatSession(), 1000);
      } else if (isNetworkError) {
        if (currentLanguage === "hi-IN") {
          fallbackMsg = "‡§ï‡§®‡•á‡§ï‡•ç‡§∂‡§® ‡§Æ‡•á‡§Ç ‡§∏‡§Æ‡§∏‡•ç‡§Ø‡§æ ‡§π‡•à‡•§ ‡§ï‡•É‡§™‡§Ø‡§æ ‡§Ö‡§™‡§®‡§æ ‡§á‡§Ç‡§ü‡§∞‡§®‡•á‡§ü ‡§ú‡§æ‡§Ç‡§ö‡•á‡§Ç‡•§";
        } else {
          fallbackMsg = "Connection issue. Please check your internet.";
        }
        toast.error("Network error. Check your connection.");
      } else {
        // Generic fallback for unknown errors
        if (currentLanguage === "hi-IN") {
          fallbackMsg = "‡§ï‡•ç‡§∑‡§Æ‡§æ ‡§ï‡§∞‡•á‡§Ç, ‡§Æ‡•Å‡§ù‡•á ‡§∏‡§Æ‡§ù‡§®‡•á ‡§Æ‡•á‡§Ç ‡§ï‡§†‡§ø‡§®‡§æ‡§à ‡§π‡•Å‡§à‡•§ ‡§ï‡•ç‡§Ø‡§æ ‡§Ü‡§™ ‡§´‡§ø‡§∞ ‡§∏‡•á ‡§¨‡§§‡§æ ‡§∏‡§ï‡§§‡•á ‡§π‡•à‡§Ç?";
        } else {
          fallbackMsg = "Sorry, I had trouble understanding. Could you repeat that?";
        }
      }
      
      setLastResponse(fallbackMsg);
      await speakText(fallbackMsg);
    }
  };

  // Text-to-speech - CRITICAL VOICE OUTPUT
  const speakText = (text: string): Promise<void> => {
    return new Promise((resolve) => {
      console.log("üîä SPEAKING:", text);
      console.log("üîä TEXT LENGTH:", text.length, "characters");
      
      // Validate text
      if (!text || text.trim().length === 0) {
        console.error("‚ùå Cannot speak empty text");
        setVoiceState("idle");
        voiceStateRef.current = "idle";
        resolve();
        return;
      }

      // CRITICAL: Cancel any ongoing speech
      window.speechSynthesis.cancel();

      const utterance = new SpeechSynthesisUtterance(text);
      
      // Configure voice for calm, mindful tone
      utterance.rate = 0.9; // Slower for clarity
      utterance.pitch = 1.0;
      utterance.volume = 1.0;
      utterance.lang = currentLanguage;

      // Try to use a suitable voice
      const voices = window.speechSynthesis.getVoices();
      const preferredVoice = voices.find(voice => 
        voice.lang.startsWith(currentLanguage.split("-")[0])
      );
      
      if (preferredVoice) {
        utterance.voice = preferredVoice;
        console.log("üîä Using voice:", preferredVoice.name);
      }

      utterance.onstart = () => {
        console.log("üîä STATE: Speaking started");
        setVoiceState("speaking");
        voiceStateRef.current = "speaking";
      };

      utterance.onend = () => {
        console.log("‚úÖ STATE: Speaking finished - COMPLETE");
        setVoiceState("idle");
        voiceStateRef.current = "idle";
        
        // CRITICAL: Auto-resume listening after speaking (only if call is active)
        if (isCallActive) {
          console.log("üîÑ Auto-resuming listening in 1.5 seconds...");
          setTimeout(() => {
            if (voiceStateRef.current === "idle" && isCallActive) {
              startListening();
            }
          }, 1500);
        }
        
        resolve();
      };

      utterance.onerror = (error) => {
        console.error("‚ùå Speech synthesis error:", error);
        console.error("Error details:", JSON.stringify(error, null, 2));
        setVoiceState("idle");
        voiceStateRef.current = "idle";
        
        // Still try to resume listening
        if (isCallActive) {
          setTimeout(() => startListening(), 1000);
        }
        
        resolve();
      };

      // Add boundary event to detect progress
      utterance.onboundary = (event) => {
        console.log("üîä Speaking progress:", event.charIndex, "/", text.length);
      };

      synthRef.current = utterance;
      
      // CRITICAL: Actually speak
      try {
        window.speechSynthesis.speak(utterance);
        console.log("‚úÖ Speech queued successfully");
        
        // Add a watchdog to detect if speech is stuck
        const watchdog = setTimeout(() => {
          if (window.speechSynthesis.speaking) {
            console.log("‚ö†Ô∏è Speech still running after 30s");
          }
        }, 30000);
        
        utterance.onend = () => {
          clearTimeout(watchdog);
          console.log("‚úÖ STATE: Speaking finished - COMPLETE");
          setVoiceState("idle");
          voiceStateRef.current = "idle";
          
          if (isCallActive) {
            console.log("üîÑ Auto-resuming listening in 1.5 seconds...");
            setTimeout(() => {
              if (voiceStateRef.current === "idle" && isCallActive) {
                startListening();
              }
            }, 1500);
          }
          
          resolve();
        };
      } catch (error) {
        console.error("‚ùå Failed to queue speech:", error);
        setVoiceState("idle");
        voiceStateRef.current = "idle";
        resolve();
      }
    });
  };

  // Change language
  const toggleLanguage = () => {
    const languages = ["en-IN", "hi-IN"];
    const currentIndex = languages.indexOf(currentLanguage);
    const nextIndex = (currentIndex + 1) % languages.length;
    setCurrentLanguage(languages[nextIndex]);
    toast.success(`Language changed to ${languages[nextIndex] === "en-IN" ? "English" : "Hindi"}`);
  };

  // Cleanup on unmount
  useEffect(() => {
    return () => {
      console.log("üßπ Cleaning up voice chat");
      setIsCallActive(false);
      recognitionRef.current?.stop();
      window.speechSynthesis.cancel();
    };
  }, []);

  // Update ref when state changes
  useEffect(() => {
    voiceStateRef.current = voiceState;
  }, [voiceState]);

  // Get status message
  const getStatusMessage = () => {
    switch (voiceState) {
      case "listening":
        return "Listening to you...";
      case "speaking":
        return "Saarthi is speaking...";
      case "processing":
        return "Processing...";
      default:
        return "Tap microphone to start";
    }
  };

  // Get status color
  const getStatusColor = () => {
    switch (voiceState) {
      case "listening":
        return "from-green-500 to-emerald-600";
      case "speaking":
        return "from-blue-500 to-cyan-600";
      case "processing":
        return "from-purple-500 to-pink-600";
      default:
        return "from-gray-400 to-gray-500";
    }
  };

  return (
    <motion.div
      className="fixed inset-0 bg-black/60 backdrop-blur-md z-50 flex items-center justify-center p-4"
      initial={{ opacity: 0 }}
      animate={{ opacity: 1 }}
      exit={{ opacity: 0 }}
      onClick={onClose}
    >
      <motion.div
        onClick={(e) => e.stopPropagation()}
        initial={{ scale: 0.9, y: 20 }}
        animate={{ scale: 1, y: 0 }}
        exit={{ scale: 0.9, y: 20 }}
        className="w-full max-w-md"
      >
        <Card className="bg-gradient-to-br from-indigo-50 to-purple-50 dark:from-gray-900 dark:to-indigo-950 border-0 shadow-2xl overflow-hidden">
          {/* Header */}
          <div className="bg-gradient-to-r from-indigo-600 to-purple-600 p-6 text-center relative">
            <Button
              onClick={onClose}
              variant="ghost"
              size="icon"
              className="absolute top-4 right-4 text-white hover:bg-white/20"
            >
              <PhoneOff className="w-5 h-5" />
            </Button>

            <div className="flex flex-col items-center gap-2">
              <div className="w-20 h-20 rounded-full bg-white/20 backdrop-blur flex items-center justify-center ring-4 ring-white/30 mb-2">
                <motion.div
                  animate={voiceState === "speaking" ? { scale: [1, 1.2, 1] } : {}}
                  transition={{ duration: 1, repeat: Infinity }}
                >
                  <Volume2 className="w-10 h-10 text-white" />
                </motion.div>
              </div>
              <h2 className="text-2xl font-bold text-white">AI Saarthi</h2>
              <p className="text-white/90 text-sm">Your Calm Wellness Guide</p>
              <Badge className="bg-white/20 text-white border-white/30 mt-2">
                {currentLanguage === "en-IN" ? "üáÆüá≥ English" : "üáÆüá≥ ‡§π‡§ø‡§Ç‡§¶‡•Ä"}
              </Badge>
            </div>
          </div>

          {/* Voice State Display */}
          <div className="p-8">
            {/* Status Badge */}
            <div className="text-center mb-6">
              <motion.div
                className={`inline-flex items-center gap-2 px-4 py-2 rounded-full bg-gradient-to-r ${getStatusColor()} text-white text-sm font-medium shadow-lg`}
                animate={{ scale: [1, 1.05, 1] }}
                transition={{ duration: 2, repeat: Infinity }}
              >
                {voiceState === "listening" && <Mic className="w-4 h-4 animate-pulse" />}
                {voiceState === "speaking" && <Volume2 className="w-4 h-4 animate-pulse" />}
                {getStatusMessage()}
              </motion.div>
            </div>

            {/* Visual Feedback */}
            <div className="relative h-32 flex items-center justify-center mb-6">
              <AnimatePresence>
                {voiceState === "listening" && (
                  <motion.div
                    initial={{ opacity: 0, scale: 0.5 }}
                    animate={{ opacity: 1, scale: 1 }}
                    exit={{ opacity: 0, scale: 0.5 }}
                    className="absolute"
                  >
                    <motion.div
                      className="w-24 h-24 rounded-full bg-gradient-to-br from-green-400 to-emerald-500 opacity-30"
                      animate={{ scale: [1, 1.5, 1] }}
                      transition={{ duration: 2, repeat: Infinity }}
                    />
                    <motion.div
                      className="absolute inset-0 w-24 h-24 rounded-full bg-gradient-to-br from-green-500 to-emerald-600 opacity-50"
                      animate={{ scale: [1, 1.3, 1] }}
                      transition={{ duration: 2, repeat: Infinity, delay: 0.5 }}
                    />
                  </motion.div>
                )}

                {voiceState === "speaking" && (
                  <motion.div
                    initial={{ opacity: 0, scale: 0.5 }}
                    animate={{ opacity: 1, scale: 1 }}
                    exit={{ opacity: 0, scale: 0.5 }}
                    className="flex gap-2"
                  >
                    {[...Array(5)].map((_, i) => (
                      <motion.div
                        key={i}
                        className="w-2 bg-gradient-to-t from-blue-500 to-cyan-500 rounded-full"
                        animate={{
                          height: [20, 60, 20],
                        }}
                        transition={{
                          duration: 0.8,
                          repeat: Infinity,
                          delay: i * 0.1,
                        }}
                      />
                    ))}
                  </motion.div>
                )}

                {voiceState === "processing" && (
                  <motion.div
                    initial={{ opacity: 0 }}
                    animate={{ opacity: 1, rotate: 360 }}
                    exit={{ opacity: 0 }}
                    transition={{ rotate: { duration: 2, repeat: Infinity, ease: "linear" } }}
                    className="w-16 h-16 border-4 border-purple-500 border-t-transparent rounded-full"
                  />
                )}

                {voiceState === "idle" && (
                  <motion.div
                    initial={{ opacity: 0, scale: 0.5 }}
                    animate={{ opacity: 1, scale: 1 }}
                    className="w-24 h-24 rounded-full bg-gradient-to-br from-indigo-400 to-purple-500 flex items-center justify-center"
                  >
                    <Phone className="w-12 h-12 text-white" />
                  </motion.div>
                )}
              </AnimatePresence>
            </div>

            {/* Transcript Display */}
            <AnimatePresence>
              {(transcript || lastResponse) && (
                <motion.div
                  initial={{ opacity: 0, y: 10 }}
                  animate={{ opacity: 1, y: 0 }}
                  exit={{ opacity: 0, y: -10 }}
                  className="mb-6 space-y-3"
                >
                  {transcript && (
                    <div className="bg-white dark:bg-gray-800 rounded-xl p-4 shadow-md">
                      <p className="text-xs text-gray-500 dark:text-gray-400 mb-1">You said:</p>
                      <p className="text-sm text-gray-800 dark:text-gray-200">{transcript}</p>
                    </div>
                  )}
                  {lastResponse && (
                    <div className="bg-gradient-to-r from-indigo-100 to-purple-100 dark:from-indigo-900/50 dark:to-purple-900/50 rounded-xl p-4 shadow-md">
                      <p className="text-xs text-indigo-600 dark:text-indigo-400 mb-1">Saarthi:</p>
                      <p className="text-sm text-gray-800 dark:text-gray-200 leading-relaxed">{lastResponse}</p>
                    </div>
                  )}
                </motion.div>
              )}
            </AnimatePresence>

            {/* Controls */}
            <div className="flex gap-4 justify-center items-center flex-wrap">
              {/* Main Mic Button */}
              <motion.div whileTap={{ scale: 0.95 }}>
                <Button
                  onClick={voiceState === "listening" ? stopListening : startListening}
                  disabled={voiceState === "speaking" || voiceState === "processing" || !isSupported || !isCallActive}
                  size="lg"
                  className={`w-20 h-20 rounded-full shadow-2xl ${
                    voiceState === "listening"
                      ? "bg-gradient-to-br from-red-500 to-red-600 hover:from-red-600 hover:to-red-700"
                      : "bg-gradient-to-br from-green-500 to-emerald-600 hover:from-green-600 hover:to-emerald-700"
                  }`}
                >
                  {voiceState === "listening" ? (
                    <MicOff className="w-8 h-8 text-white" />
                  ) : (
                    <Mic className="w-8 h-8 text-white" />
                  )}
                </Button>
              </motion.div>

              {/* Retry Button - shown when call is not active */}
              {!isCallActive && (
                <motion.div whileTap={{ scale: 0.95 }}>
                  <Button
                    onClick={initializeChatSession}
                    variant="outline"
                    className="rounded-full px-6 py-3 text-sm border-2 border-indigo-500 text-indigo-600 hover:bg-indigo-50 dark:text-indigo-400 dark:hover:bg-indigo-950"
                  >
                    üîÑ Retry Connection
                  </Button>
                </motion.div>
              )}

              {/* Test API Button - for debugging */}
              {isCallActive && voiceState === "idle" && (
                <motion.div whileTap={{ scale: 0.95 }}>
                  <Button
                    onClick={async () => {
                      console.log("üß™ Testing API with simple message...");
                      await getAIResponse("Hello");
                    }}
                    variant="outline"
                    size="sm"
                    className="rounded-full px-4 py-2 text-xs border border-gray-300"
                  >
                    üß™ Test API
                  </Button>
                </motion.div>
              )}

              {/* Language Toggle */}
              <Button
                onClick={toggleLanguage}
                variant="outline"
                className="rounded-full px-4 py-2 text-sm"
                disabled={voiceState !== "idle"}
              >
                {currentLanguage === "en-IN" ? "Switch to Hindi" : "Switch to English"}
              </Button>
            </div>

            {/* Help Text */}
            <div className="mt-6 text-center">
              <p className="text-xs text-gray-600 dark:text-gray-400 leading-relaxed">
                {!isCallActive 
                  ? "‚ö†Ô∏è Connection failed. Click 'Retry Connection' to try again."
                  : voiceState === "idle" 
                  ? "Tap the microphone to start talking with Saarthi"
                  : voiceState === "listening"
                  ? "Speak naturally... Saarthi is listening"
                  : voiceState === "speaking"
                  ? "Listen to Saarthi's response..."
                  : "Saarthi is thinking..."}
              </p>
            </div>
          </div>

          {/* Footer */}
          <div className="bg-gradient-to-r from-indigo-100 to-purple-100 dark:from-gray-800 dark:to-indigo-900 px-6 py-4 text-center border-t border-indigo-200 dark:border-indigo-800">
            <p className="text-xs text-gray-600 dark:text-gray-400">
              üéôÔ∏è Browser-based voice chat ‚Ä¢ 100% Free ‚Ä¢ Web Speech API
            </p>
          </div>
        </Card>
      </motion.div>
    </motion.div>
  );
};
